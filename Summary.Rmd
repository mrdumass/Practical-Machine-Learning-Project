in---
title: "Report"
output: pdf_document
date: "October 24, 2014"
---

First Load in the required packages
```{r}
require(caret)
require(ggplot2)
require(randomForest)
```

Read in the Training and Test Set.
```{r}
training_URL<-"http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
test_URL<-"http://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
training<-read.csv(training_URL,na.strings=c("NA",""))
test<-read.csv(test_URL,na.strings=c("NA",""))
```

Now get rid of the columns that is simply an index, timestamp or username.
```{r}
training<-training[,7:160]
test<-test[,7:160]
```

Remove the columns that are mostly NAs. They could be useful in the model, but it is easier to cut the data.frame down and see if it gives good results
```{r}
mostly_data<-apply(!is.na(training),2,sum)>19621
training<-training[,mostly_data]
test<-test[,mostly_data]
dim(training)
```
I partitioned the training set into a smaller set caller training1 really to speed up the running of the model
```{r}
InTrain<-createDataPartition(y=training$classe,p=0.3,list=FALSE)
training1<-training[InTrain,]
```
So I decided to use caret with random forest as my model with 5 fold cross validation
```{r}
rf_model<-train(classe~.,data=training1,method="rf",
                trControl=trainControl(method="cv",number=5),
                prox=TRUE,allowParallel=TRUE)
print(rf_model)
print(rf_model$finalModel)
```
That is a pretty amazingly good model! .987 accuracy! I usually hope for something in the >.7 in my real work. submitted this model with my prediction on the test set and got 20 out of 20.
```{r}
pred<-predict(rf_model,newdata=test)
print(pred)
```

